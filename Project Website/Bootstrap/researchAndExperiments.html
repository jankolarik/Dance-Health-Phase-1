<!DOCTYPE html>
<html lang="en">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">

  <title>Dance Health</title>

  <!-- Bootstrap core CSS -->
  <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Custom styles for this template -->
  <link href="css/modern-business.css" rel="stylesheet">

  <!--Table Style-->
  <style>table, th, td {
    border: 1px solid black;
    border-collapse: collapse;
    }
    th, td {
    padding: 15px;
    }
    </style>

</head>

<div>

  <!-- Navigation -->
  <nav class="navbar fixed-top navbar-expand-lg navbar-dark bg-dark fixed-top">
    <div class="container">
      <a class="navbar-brand" href="index.html">Home</a>
      <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarResponsive">
        <ul class="navbar-nav ml-auto">
          <li class="nav-item">
            <a class="nav-link" href="requirements.html">Requirements</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="researchAndExperiments.html">Research & Experiments</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="algorithms.html">Algorithms</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="design.html">Design</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="testing.html">Testing</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="evaluation.html">Evaluation</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="appendices.html">Appendices</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="contact.html">Contact</a>
          </li>
          <li class="nav-item dropdown">
            <a class="nav-link dropdown-toggle" href="#" id="navbarDropdownBlog" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
              HCI
            </a>
            <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdownBlog">
              <a class="dropdown-item" href="userRequirementsHCI.html">User Requirements</a>
              <a class="dropdown-item" href="personasAndSketchesHCI.html">Personas and Sketches</a>

            </div>
          </li>

        </ul>
      </div>
    </div>
  </nav>

  <!-- Page Content -->
  <div class="container">

        <!-- Page Heading/Breadcrumbs -->
        <h1 class="mt-4 mb-3">Research and Experiments</h1>
    
        <ol class="breadcrumb">
          <li class="breadcrumb-item">
            <a href="index.html">Home</a>
          </li>
          <li class="breadcrumb-item active">Research and Experiments</li>
        </ol>
    
        <h3>Related Projects</h3>
        <p>After reasearching similar projects online we have found several articles which have similar goals with us. Thus we picked up two articels we think is most appropiate to compare with and comes up with following reviews.</p>

        <h4><b>Dance Analysis using Multiple Kinect Sensors</b></h4>
        <h5>by A. Kitsikidis et. al.</h5>
        <p>After viewing the whole paper we found there were quite a lot of useful information in it. It was extremely applicable to us, as the researchers used the same cameras as us, to the same or similar ends.</p>
        <p>The first part of the article is about calibration and fusion of using multiple kinect devices at the same time, due to the fact that the latest Kinect Azure synchronise sensors stream from multiple Kinect devices easily, so we decided not to go too deep with this part.</p>
        <p>Then the next part is about motion analysis, their way of dividing whole body parts into five sub parts and analysing them separately to obtain a result posture is a clever way to do it and we think this is a possible approach to take in our project as well. Even though we are not so familiar with machine learning, but we will make some notes about their method and potentially use it in the later part of the project.</p>
        <p>It was interesting to learn how one can maneuver around occlusions while performing skeletal tracking with Kinect cameras. This will be specifically helpful to us as the styles of dancing we are tracking are in pairs/couples, and we expect occlusions will happen fairly often.</p>
        <p>In terms of their testing result, there are a couple of issues with this. First of all, this was set-up to just target a single dance, whereas our project encapsulates many more dances. Furthermore, the dance that is described in the paper was relatively easy to perform thus might have been the reason why they reached reasonable accuracy. </p>
        <p>In conclusion, the paper was a helpful insight in skeletal tracking specifically for dance with Kinect cameras, tailoring said tracking to a specific dance style, and dealing with object or human occlusions while tracking a dancer, and it will be considered in the development of our project.</p>

        <h4><b>Development of an automated exercise detection and evaluation system using the kinect depth camera</b></h4>
        <h5>master thesis, twente university, Frodo Muijzer</h5>
        <p>This article is describing the way to use Microsoft Kinect camera for automated rehabilitation exercise evaluation. The evaluation process is using the parameter that have been explicitly defined by a new parameterization method based on Labanotation. Due to the huge amount of information this article includes, only a few sections of this article is gonna be used.</p>
        <p>The first part is introducing the basic concepts about Kinect sensor, it go through the way Kinect recognise joints data from camera and also accuracy problem that occur at the same time. It contains some ideas that we are agreed with after our own testing, like the difficulty of recognising some specific body movements due to joints occlusion.</p>
        <p>Then the next part is about choosing the suitable exercise for evaluation, even though these information are not related to our project goals, but their evaluation result show us the potential challenge we might face in our projects. Some rehabilitation movements are very simple to perform for human being, but it’s hard for Kinect to capture and also difficult to parameterize.</p>
        <p>Comparing to our project background, dance movements have a greater complexity and uncertainty than rehabilitation movements, which is going to make it much harder to evaluate.</p>
        <p>The last part we are interested at is the Parameterization of exercises. They are specifically defining each movement by a sequence of changing of joint positions and the angles between them. This system requires a lot of effort to build and hard to add new movements. However, it provides us with some insight about how to process and combine separate joints data into body posture. These information could be useful when we start building posture recognition function.</p>
        <p>In conclusion, this articles helped us understand more about different possible ways to use data gathered from Kinect Sensor, and also identify some potential challenges we may face in our projects.</p>
      
        <h3>Related Technologies</h3>
        <p>Comparison sheet between Kinect 2, iPhone X and iPhone 11 Pro</p>
        <table style="width:100%">
            <colspn >
            <tr>
                <th width="25%">Aspect</th>
                <th width="25%">Kinect 2</th>
                <th width="25%">iPhone X</th>
                <th width="25%">iPhone 11 Pro</th>
            </tr>
            <tr>
                <td>Price</td>
                <td>Approx £100 (cable + camera)</td>
                <td>Approx £400</td>
                <td>Approx £1200</td>
            </tr>
            <tr>
                <td>FPS</td>
                <td>30</td>
                <td>240</td>
                <td>240</td>
            </tr>
            <tr>
                <td>Video</td>
                <td><a href="http://bit.ly/33v5kjB">Kinect 2 Video</a></td>
                <td><a href="http://bit.ly/2R3oB9g">iPhone X Video</a></td>
                <td>To be recorded if the department provides us the equipment</td>
            </tr>
            <tr>
                <td>Time Of Flight Sensors</td>
                <td>Yes</td>
                <td>No</td>
                <td>Yes</td>
            </tr>
            <tr>
                <td>Built in multi-people recording</td>
                <td>Yes</td>
                <td>No</td>
                <td>No</td>
            </tr>
            <tr>
                <td>Kinect Azure compatibility</td>
                <td>Yes</td>
                <td>No</td>
                <td>No</td>
            </tr>
            <tr>
                <td>SDK licensing availability</td>
                <td>Not need (product no longer sold, will be needed for Azure) </td>
                <td>Yes</td>
                <td>Yes</td>
            </tr>
            <tr>
                <td>Communication with the Apple Watch</td>
                <td>No</td>
                <td>Yes</td>
                <td>Yes</td>
            </tr>
            <tr>
                <td>Requires laptop/computer to start:</td>
                <td>Yes</td>
                <td>No</td>
                <td>No</td>
            </tr>
            <tr>
                <td>Requires power supply:</td>
                <td>Yes</td>
                <td>No</td>
                <td>No</td>
            </tr>
            </colspn>
        </table>
<br/>
      <h3>Experimenting with Cameras</h3>
    <p>We tested the Kinect and iPhone cameras side by side in videos to share the full experience with our partners at Arthur Murray Dance Centers.</p>
    <div class="col-lg-6">
      <iframe width="700" height="450" src="https://www.youtube.com/embed/7ev9H3-h-ls" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
        <iframe src="https://drive.google.com/file/d/1JwX1dwRbUFr5elfGEACitAY1P1Yy3EXF/preview" width="700" height="480" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
  </div>
        <p></p>
        <h3>Conclusion</h3>
        <p>We also compared with Intel Real Sense, and the latest Kinect Azure camera, the optimial solution is the Kinect Azure which is the newest realsed one with brand new SDK come with it and is also capable of synchronise multiple cameras which hugely improve the data accuracy and reduce occlusion problem. However we are not able to get it in UK so we choose to use Kinect 2 camera which is compatible with the Azure camera.</p>

        <h3>Alternative Algorithms (merging)</h3>

        <h3>Alternative Libraries (Kinect UI)</h3>

        <h3>Summary</h3>


      </div>
</div>>
</div>
      <!-- /.container -->

  <!-- Footer -->
  <footer class="py-5 bg-dark">
    <div class="container">
      <p class="m-0 text-center text-white">Copyright &copy; Team 32, 2020</p>
    </div>
    <!-- /.container -->
  </footer>

  <!-- Bootstrap core JavaScript -->
  <script src="vendor/jquery/jquery.min.js"></script>
  <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

</body>

</html>
